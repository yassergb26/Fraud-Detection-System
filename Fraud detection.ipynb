{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1ffa1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6961 - accuracy: 0.5000 - val_loss: 0.7424 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6885 - accuracy: 0.5000 - val_loss: 0.7446 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6821 - accuracy: 0.5278 - val_loss: 0.7463 - val_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6763 - accuracy: 0.5278 - val_loss: 0.7471 - val_accuracy: 0.2500\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6706 - accuracy: 0.5833 - val_loss: 0.7481 - val_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6649 - accuracy: 0.6389 - val_loss: 0.7488 - val_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6598 - accuracy: 0.6667 - val_loss: 0.7492 - val_accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6547 - accuracy: 0.6667 - val_loss: 0.7491 - val_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6502 - accuracy: 0.7500 - val_loss: 0.7486 - val_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6451 - accuracy: 0.7778 - val_loss: 0.7477 - val_accuracy: 0.2500\n",
      "Test Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "df = pd.read_excel('SampleData.xlsx', header=1)  \n",
    "\n",
    "\n",
    "df['Date_Time'] = pd.to_datetime(df['Date_Time'])\n",
    "\n",
    "\n",
    "df['hour'] = df['Date_Time'].dt.hour\n",
    "\n",
    "df['indicator-2'] = df['indicator-2'].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "categorical_cols = ['Decision', 'Merchant_State', 'Type']\n",
    "numerical_cols = ['a-score', 'b-score', 'Category', 'indicator-1', 'C-score', 'indicator-2', 'vol-1', 'vol-2']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "y = df['Fraud'].astype(int)\n",
    "\n",
    "\n",
    "X = df.drop(['Fraud', 'Date_Time', 'CreditCard#'], axis=1)  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train_preprocessed = X_train_preprocessed.reshape((X_train_preprocessed.shape[0], 1, X_train_preprocessed.shape[1]))\n",
    "X_test_preprocessed = X_test_preprocessed.reshape((X_test_preprocessed.shape[0], 1, X_test_preprocessed.shape[1]))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(32, input_shape=(X_train_preprocessed.shape[1], X_train_preprocessed.shape[2]), return_sequences=True))\n",
    "model.add(GRU(16))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train_preprocessed, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(X_test_preprocessed, y_test, verbose=0)\n",
    "print('Test Accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e721df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ym221\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/data/my_preprocessor.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('/mnt/data/my_model.h5')\n",
    "\n",
    "\n",
    "from joblib import dump\n",
    "dump(preprocessor, '/mnt/data/my_preprocessor.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "182c4647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "      IDs  Predicted_Fraud\n",
      "0  R3ts55                1\n",
      "1  12ts55                0\n",
      "2  R3ts55                0\n",
      "3  12ts55                0\n",
      "4  R3ts55                0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "predict_df = pd.read_excel('SampleData-Predict.xlsx')\n",
    "\n",
    "\n",
    "predict_df['Date_Time'] = pd.to_datetime(predict_df['Date_Time'])\n",
    "predict_df['hour'] = predict_df['Date_Time'].dt.hour\n",
    "\n",
    "\n",
    "indicator_2_series = predict_df['indicator-2'].astype(str).str.extract(r'(\\d+)',expand=False)\n",
    "indicator_2_series = indicator_2_series.dropna().astype(float) \n",
    "predict_df['indicator-2'] = indicator_2_series\n",
    "\n",
    "\n",
    "numerical_cols = ['a-score', 'b-score', 'Category', 'indicator-1', 'C-score', 'indicator-2', 'vol-1', 'vol-2']\n",
    "categorical_cols = ['Decision', 'Merchant_State', 'Type']\n",
    "\n",
    "\n",
    "preprocessor = load('my_preprocessor.joblib')\n",
    "\n",
    "\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "\n",
    "X_predict = predict_df[numerical_cols + categorical_cols]\n",
    "\n",
    "\n",
    "X_predict_preprocessed = preprocessor.transform(X_predict)\n",
    "X_predict_preprocessed = X_predict_preprocessed.reshape((X_predict_preprocessed.shape[0], 1, X_predict_preprocessed.shape[1]))\n",
    "\n",
    "\n",
    "predictions = model.predict(X_predict_preprocessed)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "\n",
    "predict_df['Predicted_Fraud'] = predicted_classes\n",
    "\n",
    "\n",
    "print(predict_df[['IDs', 'Predicted_Fraud']].head())\n",
    "\n",
    "\n",
    "predict_df.to_excel('/mnt/data/Predicted_SampleData.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5242c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a54fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77357943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
